{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e401b8",
   "metadata": {
    "id": "31e401b8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import uuid\n",
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "LecvC2KbhRRz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LecvC2KbhRRz",
    "outputId": "05ae62bd-7ecf-4e34-a528-be1f8a634d34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Traffic-Signs-Detection-Testing'...\n",
      "remote: Enumerating objects: 38, done.\u001b[K\n",
      "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 38 (delta 0), reused 2 (delta 0), pack-reused 34\u001b[K\n",
      "Unpacking objects: 100% (38/38), done.\n",
      "/content/Traffic-Signs-Detection-Testing/notebook\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Uncomment the below code if you are using google colab.\n",
    "\"\"\"\n",
    "\n",
    "# !git clone https://github.com/shubhamgantayat/Traffic-Signs-Detection-Testing.git\n",
    "# %cd Traffic-Signs-Detection-Testing/notebook/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vW3PkaHJhkMG",
   "metadata": {
    "id": "vW3PkaHJhkMG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bg5YVUWhtlt",
   "metadata": {
    "id": "2bg5YVUWhtlt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f21f93bd",
   "metadata": {
    "id": "f21f93bd"
   },
   "outputs": [],
   "source": [
    "ZIP_TRAIN_PATH = \"../raw_data/train.pickle.zip\"\n",
    "ZIP_VALID_PATH = \"../raw_data/valid.pickle.zip\"\n",
    "ZIP_TEST_PATH = \"../raw_data/test.pickle.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2eb9a92",
   "metadata": {
    "id": "f2eb9a92"
   },
   "outputs": [],
   "source": [
    "def unzip_file(src, dest):\n",
    "    with ZipFile(src, \"r\") as f:\n",
    "        f.extractall(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "231b236b",
   "metadata": {
    "id": "231b236b"
   },
   "outputs": [],
   "source": [
    "unzip_file(ZIP_TRAIN_PATH, \"../raw_data/\")\n",
    "unzip_file(ZIP_VALID_PATH, \"../raw_data/\")\n",
    "unzip_file(ZIP_TEST_PATH, \"../raw_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a5efbca",
   "metadata": {
    "id": "4a5efbca"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5bdd472",
   "metadata": {
    "id": "a5bdd472"
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"../raw_data/train.pickle\"\n",
    "VALID_PATH = \"../raw_data/valid.pickle\"\n",
    "TEST_PATH = \"../raw_data/test.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfc0ff49",
   "metadata": {
    "id": "dfc0ff49"
   },
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        d = pickle.load(f, encoding='latin1')  \n",
    "    x = d['features'].astype(np.uint8)   # 4D numpy.ndarray type, for train = (34799, 32, 32, 3)\n",
    "    y = d['labels']                        # 1D numpy.ndarray type, for train = (34799,)\n",
    "    s = d['sizes']                         # 2D numpy.ndarray type, for train = (34799, 2)\n",
    "    c = d['coords']  \n",
    "    return x, y, s, c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e728368",
   "metadata": {
    "id": "9e728368"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = {}, {}, {}\n",
    "train_data[\"x\"], train_data[\"y\"], _, train_data[\"c\"] = load_file(TRAIN_PATH)\n",
    "valid_data[\"x\"], valid_data[\"y\"], _, valid_data[\"c\"] = load_file(VALID_PATH)\n",
    "test_data[\"x\"], test_data[\"y\"], _, test_data[\"c\"] = load_file(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77a3c6f3",
   "metadata": {
    "id": "77a3c6f3"
   },
   "outputs": [],
   "source": [
    "def display(img, coordinates):\n",
    "    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    cv2.rectangle(new_img, \n",
    "                  (coordinates[0], coordinates[1]),\n",
    "                  (coordinates[0] + coordinates[2], coordinates[1] + coordinates[3]),\n",
    "                  (255,0,0),\n",
    "                  1\n",
    "                 )\n",
    "    while True:\n",
    "        cv2.imshow(\"img\", new_img)\n",
    "        if cv2.waitKey(0) & 0xFF == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4923d9d",
   "metadata": {
    "id": "a4923d9d"
   },
   "outputs": [],
   "source": [
    "# display(train_data[\"x\"][4000], train_data[\"c\"][4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dae9e1d4",
   "metadata": {
    "id": "dae9e1d4"
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"../raw_data/label_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21c1b079",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "21c1b079",
    "outputId": "36601da7-75ac-4b2d-c6b2-961d9bb3300e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8d6b4d05-5d53-40a1-afad-dca611f0583e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClassId</th>\n",
       "      <th>SignName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Speed limit (20km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Speed limit (30km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Speed limit (50km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Speed limit (60km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Speed limit (70km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Speed limit (80km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>End of speed limit (80km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Speed limit (100km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Speed limit (120km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>No passing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>No passing for vehicles over 3.5 metric tons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Right-of-way at the next intersection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Priority road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Yield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>No vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Vehicles over 3.5 metric tons prohibited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>No entry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>General caution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Dangerous curve to the left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Dangerous curve to the right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Double curve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Bumpy road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Slippery road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Road narrows on the right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Road work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Traffic signals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Pedestrians</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Children crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Bicycles crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>Beware of ice/snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Wild animals crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>End of all speed and passing limits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Turn right ahead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>Turn left ahead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>Ahead only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>Go straight or right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>Go straight or left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>Keep right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>Keep left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>Roundabout mandatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>End of no passing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>End of no passing by vehicles over 3.5 metric ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d6b4d05-5d53-40a1-afad-dca611f0583e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8d6b4d05-5d53-40a1-afad-dca611f0583e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8d6b4d05-5d53-40a1-afad-dca611f0583e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    ClassId                                           SignName\n",
       "0         0                               Speed limit (20km/h)\n",
       "1         1                               Speed limit (30km/h)\n",
       "2         2                               Speed limit (50km/h)\n",
       "3         3                               Speed limit (60km/h)\n",
       "4         4                               Speed limit (70km/h)\n",
       "5         5                               Speed limit (80km/h)\n",
       "6         6                        End of speed limit (80km/h)\n",
       "7         7                              Speed limit (100km/h)\n",
       "8         8                              Speed limit (120km/h)\n",
       "9         9                                         No passing\n",
       "10       10       No passing for vehicles over 3.5 metric tons\n",
       "11       11              Right-of-way at the next intersection\n",
       "12       12                                      Priority road\n",
       "13       13                                              Yield\n",
       "14       14                                               Stop\n",
       "15       15                                        No vehicles\n",
       "16       16           Vehicles over 3.5 metric tons prohibited\n",
       "17       17                                           No entry\n",
       "18       18                                    General caution\n",
       "19       19                        Dangerous curve to the left\n",
       "20       20                       Dangerous curve to the right\n",
       "21       21                                       Double curve\n",
       "22       22                                         Bumpy road\n",
       "23       23                                      Slippery road\n",
       "24       24                          Road narrows on the right\n",
       "25       25                                          Road work\n",
       "26       26                                    Traffic signals\n",
       "27       27                                        Pedestrians\n",
       "28       28                                  Children crossing\n",
       "29       29                                  Bicycles crossing\n",
       "30       30                                 Beware of ice/snow\n",
       "31       31                              Wild animals crossing\n",
       "32       32                End of all speed and passing limits\n",
       "33       33                                   Turn right ahead\n",
       "34       34                                    Turn left ahead\n",
       "35       35                                         Ahead only\n",
       "36       36                               Go straight or right\n",
       "37       37                                Go straight or left\n",
       "38       38                                         Keep right\n",
       "39       39                                          Keep left\n",
       "40       40                               Roundabout mandatory\n",
       "41       41                                  End of no passing\n",
       "42       42  End of no passing by vehicles over 3.5 metric ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4694f70",
   "metadata": {
    "id": "f4694f70"
   },
   "source": [
    "# Augmentation 1 - Local Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "755abe36",
   "metadata": {
    "id": "755abe36"
   },
   "outputs": [],
   "source": [
    "def local_histogram_equalization(img):\n",
    "    new_img = np.zeros(img.shape, dtype=np.uint8)\n",
    "    new_img[:,:,0] = cv2.equalizeHist(img[:,:,0])\n",
    "    new_img[:,:,1] = cv2.equalizeHist(img[:,:,1])\n",
    "    new_img[:,:,2] = cv2.equalizeHist(img[:,:,2])\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "651c6bd1",
   "metadata": {
    "id": "651c6bd1"
   },
   "outputs": [],
   "source": [
    "new_img = local_histogram_equalization(train_data['x'][4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57869e96",
   "metadata": {
    "id": "57869e96"
   },
   "outputs": [],
   "source": [
    "# display(new_img, train_data['c'][4000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff34723",
   "metadata": {
    "id": "7ff34723"
   },
   "source": [
    "# Augmentation 2 - Changing Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e1e6520",
   "metadata": {
    "id": "2e1e6520"
   },
   "outputs": [],
   "source": [
    "def change_brightness(img):\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    img_hsv[:,:,2] = img_hsv[:,:,2] * (0.5 + np.random.uniform(size=(img_hsv.shape[:-1])))\n",
    "    img_rgb = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB)\n",
    "    return img_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "067b8c24",
   "metadata": {
    "id": "067b8c24"
   },
   "outputs": [],
   "source": [
    "new_img = change_brightness(train_data['x'][4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf6d07ee",
   "metadata": {
    "id": "cf6d07ee"
   },
   "outputs": [],
   "source": [
    "# display(new_img, train_data['c'][4000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3159c5a4",
   "metadata": {
    "id": "3159c5a4"
   },
   "source": [
    "# Augmentation 3 - Rotating Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32429267",
   "metadata": {
    "id": "32429267"
   },
   "outputs": [],
   "source": [
    "def rotation_changing(image):\n",
    "    # Defining angle range\n",
    "    angle_range = 30\n",
    "    # Defining angle rotation\n",
    "    angle_rotation = np.random.uniform(angle_range) - angle_range / 2\n",
    "    # Getting shape of image\n",
    "    rows, columns, channels = image.shape\n",
    "    # Implementing rotation\n",
    "    # Calculating Affine Matrix\n",
    "    affine_matrix = cv2.getRotationMatrix2D((columns / 2, rows / 2), angle_rotation, 1)\n",
    "    # Warping original image with Affine Matrix\n",
    "    rotated_image = cv2.warpAffine(image, affine_matrix, (columns, rows))\n",
    "    # Returning rotated image\n",
    "    return rotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7154d4dd",
   "metadata": {
    "id": "7154d4dd"
   },
   "outputs": [],
   "source": [
    "new_img = rotation_changing(train_data['x'][4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76f469e4",
   "metadata": {
    "id": "76f469e4"
   },
   "outputs": [],
   "source": [
    "# display(new_img, train_data['c'][4000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f257c8",
   "metadata": {
    "id": "64f257c8"
   },
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80035f4d",
   "metadata": {
    "id": "80035f4d"
   },
   "outputs": [],
   "source": [
    "def shuffle(data, seed=0):\n",
    "    new_data = deepcopy(data)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(new_data[\"x\"])\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(new_data[\"y\"])\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(new_data[\"c\"])\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de1a50d2",
   "metadata": {
    "id": "de1a50d2"
   },
   "outputs": [],
   "source": [
    "def preprocess(data, shuffle=False, lhe=False, rotate=False, brightness=False):\n",
    "    if shuffle:\n",
    "        data = shuffle(data)\n",
    "    if lhe:\n",
    "        data[\"x\"] = list(map(local_histogram_equalization, tqdm(data[\"x\"])))\n",
    "    if rotate:\n",
    "        data[\"x\"] = list(map(rotation_changing, tqdm(data[\"x\"])))\n",
    "    if brightness:\n",
    "        data[\"x\"] = list(map(rotation_changing, tqdm(data[\"x\"])))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef40de0a",
   "metadata": {
    "id": "ef40de0a"
   },
   "outputs": [],
   "source": [
    "def join_data(data, augmented_data):\n",
    "    data[\"x\"] = np.r_[data[\"x\"], augmented_data[\"x\"]]\n",
    "    data[\"y\"] = np.r_[data[\"y\"], augmented_data[\"y\"]]\n",
    "    data[\"c\"] = np.r_[data[\"c\"], augmented_data[\"c\"]]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f54e30e",
   "metadata": {
    "id": "4f54e30e"
   },
   "outputs": [],
   "source": [
    "def generate_augmented_data(data):\n",
    "    augmented_data = None\n",
    "    list_kwargs = [\n",
    "        {\"shuffle\": False, \"lhe\": True, \"rotate\": False, \"brightness\": False},\n",
    "        {\"shuffle\": False, \"lhe\": False, \"rotate\": True, \"brightness\": False},\n",
    "        {\"shuffle\": False, \"lhe\": False, \"rotate\": False, \"brightness\": True},\n",
    "        {\"shuffle\": False, \"lhe\": True, \"rotate\": True, \"brightness\": False},\n",
    "        {\"shuffle\": False, \"lhe\": True, \"rotate\": False, \"brightness\": True},\n",
    "        {\"shuffle\": False, \"lhe\": False, \"rotate\": True, \"brightness\": True},\n",
    "        {\"shuffle\": False, \"lhe\": True, \"rotate\": True, \"brightness\": True}\n",
    "    ]\n",
    "    for kwargs in list_kwargs:\n",
    "        data = shuffle(data, np.random.randint(0,100))\n",
    "        data_top = {}\n",
    "        data_top[\"x\"] = data[\"x\"][:int(0.2*len(data[\"x\"]))]\n",
    "        data_top[\"y\"] = data[\"y\"][:int(0.2*len(data[\"x\"]))]\n",
    "        data_top[\"c\"] = data[\"c\"][:int(0.2*len(data[\"x\"]))]\n",
    "        new_data = preprocess(data_top, **kwargs)\n",
    "        if augmented_data is None:\n",
    "            augmented_data = new_data\n",
    "        else:\n",
    "            augmented_data = join_data(new_data, augmented_data)\n",
    "    return join_data(new_data, augmented_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24195fcf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24195fcf",
    "outputId": "7e5a60cc-7c31-4b68-ae98-639e7ab3a581"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6959/6959 [00:00<00:00, 43847.73it/s]\n",
      "100%|██████████| 6959/6959 [00:00<00:00, 32233.45it/s]\n",
      "100%|██████████| 6959/6959 [00:00<00:00, 43242.04it/s]\n",
      "100%|██████████| 6959/6959 [00:00<00:00, 44247.75it/s]\n",
      "100%|██████████| 6959/6959 [00:00<00:00, 38276.49it/s]\n",
      "100%|██████████| 6959/6959 [00:00<00:00, 42314.62it/s]\n",
      "100%|██████████| 6959/6959 [00:00<00:00, 38017.60it/s]\n",
      "100%|██████████| 6959/6959 [00:00<00:00, 41620.97it/s]\n",
      "100%|██████████| 6959/6959 [00:00<00:00, 37802.53it/s]\n",
      "100%|██████████| 6959/6959 [00:00<00:00, 45166.69it/s]\n",
      "100%|██████████| 6959/6959 [00:00<00:00, 40218.43it/s]\n",
      "100%|██████████| 6959/6959 [00:00<00:00, 39647.11it/s]\n",
      "100%|██████████| 882/882 [00:00<00:00, 40324.57it/s]\n",
      "100%|██████████| 882/882 [00:00<00:00, 29343.83it/s]\n",
      "100%|██████████| 882/882 [00:00<00:00, 39739.78it/s]\n",
      "100%|██████████| 882/882 [00:00<00:00, 36426.60it/s]\n",
      "100%|██████████| 882/882 [00:00<00:00, 31850.81it/s]\n",
      "100%|██████████| 882/882 [00:00<00:00, 39272.34it/s]\n",
      "100%|██████████| 882/882 [00:00<00:00, 35716.54it/s]\n",
      "100%|██████████| 882/882 [00:00<00:00, 36690.70it/s]\n",
      "100%|██████████| 882/882 [00:00<00:00, 35063.18it/s]\n",
      "100%|██████████| 882/882 [00:00<00:00, 40544.22it/s]\n",
      "100%|██████████| 882/882 [00:00<00:00, 36139.43it/s]\n",
      "100%|██████████| 882/882 [00:00<00:00, 42518.63it/s]\n"
     ]
    }
   ],
   "source": [
    "augmented_train_data = generate_augmented_data(train_data)\n",
    "augmented_valid_data = generate_augmented_data(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be01d314",
   "metadata": {
    "id": "be01d314"
   },
   "source": [
    "# Labelling Of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b7a9cd8",
   "metadata": {
    "id": "4b7a9cd8"
   },
   "outputs": [],
   "source": [
    "def convert_coordinates_to_yolo_annotation(coordinates, label, shape):\n",
    "    dh, dw, _ = shape\n",
    "    x,y,w,h = coordinates\n",
    "    x_final = x + w if x + w < dw else dw\n",
    "    y_final = y + h if y + h < dh else dh\n",
    "    x_mean = (x + x_final) / (dw * 2)\n",
    "    y_mean = (y + y_final) / (dh * 2)\n",
    "    w_norm = (x_final - x) / dw\n",
    "    h_norm = (y_final - y) / dh\n",
    "    return [\" \".join([str(label), str(x_mean), str(y_mean), str(w_norm), str(h_norm)])]\n",
    "\n",
    "def convert_yolo_annotations_to_coordinates(annotation, shape):\n",
    "    dh, dw, _ = shape\n",
    "    _, x, y, w, h = [float(i) for i in annotation[0].strip().split()]\n",
    "    x_start = (x - w / 2) * dw\n",
    "    y_start = (y - h / 2) * dh\n",
    "    return np.array([x_start, y_start, w * dw, h * dh], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4143943",
   "metadata": {
    "id": "b4143943"
   },
   "outputs": [],
   "source": [
    "annotation = convert_coordinates_to_yolo_annotation(train_data['c'][4000],\n",
    "                                       train_data['y'][4000],\n",
    "                                       train_data['x'][4000].shape\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c03831b",
   "metadata": {
    "id": "7c03831b"
   },
   "outputs": [],
   "source": [
    "new_coords = convert_yolo_annotations_to_coordinates(annotation, train_data['x'][4000].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06bd369e",
   "metadata": {
    "id": "06bd369e"
   },
   "outputs": [],
   "source": [
    "# display(train_data['x'][4000] ,new_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b85b05",
   "metadata": {
    "id": "58b85b05"
   },
   "source": [
    "# Saving new data to file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "574c37d3",
   "metadata": {
    "id": "574c37d3"
   },
   "outputs": [],
   "source": [
    "def create_directory_structure(root):\n",
    "    try:\n",
    "        os.makedirs(root, exist_ok=True)\n",
    "        folders = [\"train\", \"valid\", \"test\"]\n",
    "        for folder in folders:\n",
    "            path_to_folder = root / folder\n",
    "            os.makedirs(path_to_folder, exist_ok=True)\n",
    "            os.makedirs(path_to_folder / \"images\", exist_ok=True)\n",
    "            os.makedirs(path_to_folder / \"labels\", exist_ok=True)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7a9dfa1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b7a9dfa1",
    "outputId": "0e57f769-731d-425d-9ece-1dfcb982244e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DIR = Path(\"../data/\")\n",
    "create_directory_structure(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59b446f8",
   "metadata": {
    "id": "59b446f8"
   },
   "outputs": [],
   "source": [
    "def save_images_and_labels(path, img, label, coordinates):\n",
    "    try:\n",
    "        name = str(uuid.uuid1())\n",
    "        img_name = name + \".jpg\"\n",
    "        label_name = name + \".txt\"\n",
    "        img_path = path / \"images\" / img_name\n",
    "        label_path = path / \"labels\" / label_name\n",
    "        cv2.imwrite(str(img_path), img)\n",
    "        with open(label_path, \"w\") as f:\n",
    "            f.writelines(convert_coordinates_to_yolo_annotation(coordinates, label, img.shape))\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a0212d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a0212d0",
    "outputId": "f8825f90-df51-4b24-f4bb-18f1addb30f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97426/97426 [00:44<00:00, 2178.33it/s]\n",
      "100%|██████████| 12348/12348 [00:04<00:00, 2583.03it/s]\n",
      " 22%|██▏       | 2792/12630 [00:01<00:04, 2252.44it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  \n",
      "100%|██████████| 12630/12630 [00:05<00:00, 2309.66it/s]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_FOLDER = ROOT_DIR / \"train\"\n",
    "VALID_FOLDER = ROOT_DIR / \"valid\"\n",
    "TEST_FOLDER = ROOT_DIR / \"test\"\n",
    "train_result = list(map(lambda img, label, coordinates:save_images_and_labels(TRAIN_FOLDER, img, label, coordinates), tqdm(augmented_train_data[\"x\"]), augmented_train_data[\"y\"], augmented_train_data[\"c\"]))   \n",
    "valid_result = list(map(lambda img, label, coordinates:save_images_and_labels(VALID_FOLDER, img, label, coordinates), tqdm(augmented_valid_data[\"x\"]), augmented_valid_data[\"y\"], augmented_valid_data[\"c\"]))    \n",
    "test_result = list(map(lambda img, label, coordinates:save_images_and_labels(TEST_FOLDER, img, label, coordinates), tqdm(test_data[\"x\"]), test_data[\"y\"], test_data[\"c\"]))                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "375c792d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "375c792d",
    "outputId": "fd9c943d-a9c5-496b-d648-9b389620f7e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in test_result:\n",
    "    if i == False:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ee03425",
   "metadata": {
    "id": "1ee03425"
   },
   "outputs": [],
   "source": [
    "nc = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "854cd784",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "854cd784",
    "outputId": "71f72be8-0685-4546-da0f-638394aa095d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d1ddaeb",
   "metadata": {
    "id": "6d1ddaeb"
   },
   "outputs": [],
   "source": [
    "classes = str(list(labels[\"SignName\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e8e4d39",
   "metadata": {
    "id": "0e8e4d39"
   },
   "outputs": [],
   "source": [
    "desc = f\"\"\"train: ../data/train/images\n",
    "val: ../data/valid/images\n",
    "test: ../data/test/images\n",
    "\n",
    "nc: {nc}\n",
    "names: {classes}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"../data/data.yaml\", \"w\") as f:\n",
    "    f.write(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9l0iqDJHi--f",
   "metadata": {
    "id": "9l0iqDJHi--f"
   },
   "source": [
    "# Setting up yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "FDbXb-8HjUGI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDbXb-8HjUGI",
    "outputId": "631b8a76-58f8-455b-fa20-62b217744e4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUncomment if you are using google colab\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Uncomment if you are using google colab\n",
    "\"\"\"\n",
    "# %cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "PCBNOHocjW4V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "PCBNOHocjW4V",
    "outputId": "93d278c4-8d88-4747-d5b9-4f546c5a89d0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/Traffic-Signs-Detection-Testing'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "939d2062",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "939d2062",
    "outputId": "8f2be924-7bec-4cd0-ef72-08ae645ff893"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 13033, done.\u001b[K\n",
      "remote: Total 13033 (delta 0), reused 0 (delta 0), pack-reused 13033\u001b[K\n",
      "Receiving objects: 100% (13033/13033), 11.91 MiB | 24.79 MiB/s, done.\n",
      "Resolving deltas: 100% (9059/9059), done.\n",
      "/content/Traffic-Signs-Detection-Testing/yolov5\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5.git  # clone repo\n",
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "xvJI-AKtjYkN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "xvJI-AKtjYkN",
    "outputId": "a0717882-2435-4bff-fd1f-64b763627c98"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/Traffic-Signs-Detection-Testing/yolov5'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4VOxlg8wjj_Z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VOxlg8wjj_Z",
    "outputId": "fb347ce4-48f2-4abb-e909-47a74ef47b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |▌                               | 10 kB 24.5 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 20 kB 27.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 30 kB 11.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 40 kB 4.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 51 kB 4.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 61 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 71 kB 5.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 81 kB 5.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 92 kB 6.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 102 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 112 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 122 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 133 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 143 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 153 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 163 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 174 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 184 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 194 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 204 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 215 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 225 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 235 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 245 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 256 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 266 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 276 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 286 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 296 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 307 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 317 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 327 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 337 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 348 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 358 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 368 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 378 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 389 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 399 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 409 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 419 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 430 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 440 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 450 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 460 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 471 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 481 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 491 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 501 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 512 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 522 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 532 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 542 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 552 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 563 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 573 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 583 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 593 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 596 kB 5.4 MB/s \n",
      "\u001b[?25hSetup complete. Using torch 1.11.0+cu113 _CudaDeviceProperties(name='Tesla K80', major=3, minor=7, total_memory=11441MB, multi_processor_count=13)\n"
     ]
    }
   ],
   "source": [
    "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
    "import torch\n",
    "\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "# from utils.google_utils import gdrive_download  # to download models/datasets\n",
    "\n",
    "# clear_output()\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "IsKbuum9joFa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IsKbuum9joFa",
    "outputId": "81072e3e-8ceb-4826-d20a-09d5fd9283b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ../data/train/images\n",
      "val: ../data/valid/images\n",
      "test: ../data/test/images\n",
      "\n",
      "nc: 43\n",
      "names: ['Speed limit (20km/h)', 'Speed limit (30km/h)', 'Speed limit (50km/h)', 'Speed limit (60km/h)', 'Speed limit (70km/h)', 'Speed limit (80km/h)', 'End of speed limit (80km/h)', 'Speed limit (100km/h)', 'Speed limit (120km/h)', 'No passing', 'No passing for vehicles over 3.5 metric tons', 'Right-of-way at the next intersection', 'Priority road', 'Yield', 'Stop', 'No vehicles', 'Vehicles over 3.5 metric tons prohibited', 'No entry', 'General caution', 'Dangerous curve to the left', 'Dangerous curve to the right', 'Double curve', 'Bumpy road', 'Slippery road', 'Road narrows on the right', 'Road work', 'Traffic signals', 'Pedestrians', 'Children crossing', 'Bicycles crossing', 'Beware of ice/snow', 'Wild animals crossing', 'End of all speed and passing limits', 'Turn right ahead', 'Turn left ahead', 'Ahead only', 'Go straight or right', 'Go straight or left', 'Keep right', 'Keep left', 'Roundabout mandatory', 'End of no passing', 'End of no passing by vehicles over 3.5 metric tons']\n"
     ]
    }
   ],
   "source": [
    "%cat ../data/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "yOdMdYAIloXH",
   "metadata": {
    "id": "yOdMdYAIloXH"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"../data/data.yaml\", 'r') as stream:\n",
    "    num_classes = str(yaml.safe_load(stream)['nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "J5cCPgCbmCbi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "J5cCPgCbmCbi",
    "outputId": "51d41443-ed05-463e-e04c-957dfec541b7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'43'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "Tk6oO7f2mFL5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tk6oO7f2mFL5",
    "outputId": "50e05048-ba35-42ac-fcb7-3d54e6a782f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# YOLOv5 🚀 by Ultralytics, GPL-3.0 license\n",
      "\n",
      "# Parameters\n",
      "nc: 80  # number of classes\n",
      "depth_multiple: 0.33  # model depth multiple\n",
      "width_multiple: 0.50  # layer channel multiple\n",
      "anchors:\n",
      "  - [10,13, 16,30, 33,23]  # P3/8\n",
      "  - [30,61, 62,45, 59,119]  # P4/16\n",
      "  - [116,90, 156,198, 373,326]  # P5/32\n",
      "\n",
      "# YOLOv5 v6.0 backbone\n",
      "backbone:\n",
      "  # [from, number, module, args]\n",
      "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
      "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
      "   [-1, 3, C3, [128]],\n",
      "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
      "   [-1, 6, C3, [256]],\n",
      "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
      "   [-1, 9, C3, [512]],\n",
      "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
      "   [-1, 3, C3, [1024]],\n",
      "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
      "  ]\n",
      "\n",
      "# YOLOv5 v6.0 head\n",
      "head:\n",
      "  [[-1, 1, Conv, [512, 1, 1]],\n",
      "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
      "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
      "   [-1, 3, C3, [512, False]],  # 13\n",
      "\n",
      "   [-1, 1, Conv, [256, 1, 1]],\n",
      "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
      "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
      "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
      "\n",
      "   [-1, 1, Conv, [256, 3, 2]],\n",
      "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
      "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
      "\n",
      "   [-1, 1, Conv, [512, 3, 2]],\n",
      "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
      "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
      "\n",
      "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
      "  ]\n"
     ]
    }
   ],
   "source": [
    "%cat ../yolov5/models/yolov5s.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "_LrxBgmvmKV2",
   "metadata": {
    "id": "_LrxBgmvmKV2"
   },
   "outputs": [],
   "source": [
    "#customize iPython writefile so we can write variables\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "rP7h1BkumTT8",
   "metadata": {
    "id": "rP7h1BkumTT8"
   },
   "outputs": [],
   "source": [
    "%%writetemplate models/custom_yolov5s.yaml\n",
    "\n",
    "# parameters\n",
    "nc: {num_classes}  # number of classes\n",
    "depth_multiple: 0.33  # model depth multiple\n",
    "width_multiple: 0.50  # layer channel multiple\n",
    "\n",
    "# anchors\n",
    "anchors:\n",
    "  - [10,13, 16,30, 33,23]  # P3/8\n",
    "  - [30,61, 62,45, 59,119]  # P4/16\n",
    "  - [116,90, 156,198, 373,326]  # P5/32\n",
    "\n",
    "# YOLOv5 backbone\n",
    "backbone:\n",
    "  # [from, number, module, args]\n",
    "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
    "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
    "   [-1, 3, BottleneckCSP, [128]],\n",
    "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
    "   [-1, 9, BottleneckCSP, [256]],\n",
    "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
    "   [-1, 9, BottleneckCSP, [512]],\n",
    "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
    "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
    "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
    "  ]\n",
    "\n",
    "# YOLOv5 head\n",
    "head:\n",
    "  [[-1, 1, Conv, [512, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
    "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
    "\n",
    "   [-1, 1, Conv, [256, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
    "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
    "\n",
    "   [-1, 1, Conv, [256, 3, 2]],\n",
    "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
    "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
    "\n",
    "   [-1, 1, Conv, [512, 3, 2]],\n",
    "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
    "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
    "\n",
    "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-dmdvfZmbnK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-dmdvfZmbnK",
    "outputId": "05be8035-60bb-4df0-a9fd-781f8a8730f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Traffic-Signs-Detection-Testing/yolov5\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=./models/custom_yolov5s.yaml, data=../data/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v6.1-163-gb53917d torch 1.11.0+cu113 CUDA:0 (Tesla K80, 11441MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  3    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1    129456  models.yolo.Detect                      [43, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "custom_YOLOv5s summary: 283 layers, 7368368 parameters, 7368368 gradients, 17.2 GFLOPs\n",
      "\n",
      "Transferred 223/369 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight (no decay), 70 weight, 62 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/Traffic-Signs-Detection-Testing/yolov5/../data/train/labels.cache' images and labels... 97426 found, 0 missing, 0 empty, 0 corrupt: 100% 97426/97426 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/Traffic-Signs-Detection-Testing/yolov5/../data/valid/labels' images and labels...12348 found, 0 missing, 0 empty, 0 corrupt: 100% 12348/12348 [00:11<00:00, 1089.41it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Traffic-Signs-Detection-Testing/yolov5/../data/valid/labels.cache\n",
      "Plotting labels to runs/train/yolov5s_results2/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.81 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Image sizes 416 train, 416 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/yolov5s_results2\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/19      1.7G    0.0347   0.02193   0.07742         4       416: 100% 6090/6090 [1:01:34<00:00,  1.65it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 386/386 [02:49<00:00,  2.27it/s]\n",
      "                 all      12348      12348     0.0218      0.966      0.034     0.0187\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/19     1.91G   0.02324   0.01678   0.07536        39       416:  57% 3486/6090 [34:34<25:37,  1.69it/s]"
     ]
    }
   ],
   "source": [
    "# train yolov5s on custom data for 100 epochs\n",
    "# time its performance\n",
    "%%time\n",
    "!python train.py --img 416 --batch 16 --epochs 20 --data ../data/data.yaml --cfg ./models/custom_yolov5s.yaml --weights yolov5s.pt --name yolov5s_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pE1q5C7an_Ay",
   "metadata": {
    "id": "pE1q5C7an_Ay"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fZu2_IVDuq5H",
   "metadata": {
    "id": "fZu2_IVDuq5H"
   },
   "outputs": [],
   "source": [
    "from utils.plots import plot_results  # plot results.txt as results.png\n",
    "Image(filename='/content/Traffic-Signs-Detection-Testing/yolov5/runs/train/yolov5s_results/results.png', width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T_Zhzarwu3t3",
   "metadata": {
    "id": "T_Zhzarwu3t3"
   },
   "outputs": [],
   "source": [
    "print(\"GROUND TRUTH TRAINING DATA:\")\n",
    "Image(filename='/content/Traffic-Signs-Detection-Testing/yolov5/runs/train/yolov5s_results/val_batch0_labels.jpg', width=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KleYfF5fvAgL",
   "metadata": {
    "id": "KleYfF5fvAgL"
   },
   "outputs": [],
   "source": [
    "print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n",
    "Image(filename='/content/Traffic-Signs-Detection-Testing/yolov5/runs/train/yolov5s_results/train_batch0.jpg', width=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_OwdJk7mvU4x",
   "metadata": {
    "id": "_OwdJk7mvU4x"
   },
   "outputs": [],
   "source": [
    "%ls runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DmeE_Uv4vujV",
   "metadata": {
    "id": "DmeE_Uv4vujV"
   },
   "outputs": [],
   "source": [
    "%ls runs/train/yolov5s_results/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NP4y0HUAvx0w",
   "metadata": {
    "id": "NP4y0HUAvx0w"
   },
   "outputs": [],
   "source": [
    "%cd /content/yolov5/\n",
    "!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.5 --source ../data/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AzjimvRswG27",
   "metadata": {
    "id": "AzjimvRswG27"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for imageName in glob.glob('/content/yolov5/runs/detect/exp2*.jpg'): #assuming JPG\n",
    "    display(Image(filename=imageName))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u6kLVs1Fv53m",
   "metadata": {
    "id": "u6kLVs1Fv53m"
   },
   "source": [
    "# Saving the weights to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vcHiXiEiBc4U",
   "metadata": {
    "id": "vcHiXiEiBc4U"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "while True:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D8lz-FGjv42P",
   "metadata": {
    "id": "D8lz-FGjv42P"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irg5TxzuwOlj",
   "metadata": {
    "id": "irg5TxzuwOlj"
   },
   "outputs": [],
   "source": [
    "%cp /content/yolov5/runs/train/yolov5s_results/weights/best.pt /content/gdrive/My%20Projects/Traffic-Signs-Testing/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Traffic Signs Preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "31e401b8",
      "metadata": {
        "id": "31e401b8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from copy import deepcopy\n",
        "import uuid\n",
        "from urllib.request import urlretrieve\n",
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/shubhamgantayat/Traffic-Signs-Detection-Testing.git\n",
        "%cd Traffic-Signs-Detection-Testing/notebook/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LecvC2KbhRRz",
        "outputId": "05ae62bd-7ecf-4e34-a528-be1f8a634d34"
      },
      "id": "LecvC2KbhRRz",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Traffic-Signs-Detection-Testing'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 38 (delta 0), reused 2 (delta 0), pack-reused 34\u001b[K\n",
            "Unpacking objects: 100% (38/38), done.\n",
            "/content/Traffic-Signs-Detection-Testing/notebook\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vW3PkaHJhkMG"
      },
      "id": "vW3PkaHJhkMG",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2bg5YVUWhtlt"
      },
      "id": "2bg5YVUWhtlt",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f21f93bd",
      "metadata": {
        "id": "f21f93bd"
      },
      "outputs": [],
      "source": [
        "ZIP_TRAIN_PATH = \"../raw_data/train.pickle.zip\"\n",
        "ZIP_VALID_PATH = \"../raw_data/valid.pickle.zip\"\n",
        "ZIP_TEST_PATH = \"../raw_data/test.pickle.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f2eb9a92",
      "metadata": {
        "id": "f2eb9a92"
      },
      "outputs": [],
      "source": [
        "def unzip_file(src, dest):\n",
        "    with ZipFile(src, \"r\") as f:\n",
        "        f.extractall(dest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "231b236b",
      "metadata": {
        "id": "231b236b"
      },
      "outputs": [],
      "source": [
        "unzip_file(ZIP_TRAIN_PATH, \"../raw_data/\")\n",
        "unzip_file(ZIP_VALID_PATH, \"../raw_data/\")\n",
        "unzip_file(ZIP_TEST_PATH, \"../raw_data/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4a5efbca",
      "metadata": {
        "id": "4a5efbca"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a5bdd472",
      "metadata": {
        "id": "a5bdd472"
      },
      "outputs": [],
      "source": [
        "TRAIN_PATH = \"../raw_data/train.pickle\"\n",
        "VALID_PATH = \"../raw_data/valid.pickle\"\n",
        "TEST_PATH = \"../raw_data/test.pickle\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dfc0ff49",
      "metadata": {
        "id": "dfc0ff49"
      },
      "outputs": [],
      "source": [
        "def load_file(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        d = pickle.load(f, encoding='latin1')  \n",
        "    x = d['features'].astype(np.uint8)   # 4D numpy.ndarray type, for train = (34799, 32, 32, 3)\n",
        "    y = d['labels']                        # 1D numpy.ndarray type, for train = (34799,)\n",
        "    s = d['sizes']                         # 2D numpy.ndarray type, for train = (34799, 2)\n",
        "    c = d['coords']  \n",
        "    return x, y, s, c\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9e728368",
      "metadata": {
        "id": "9e728368"
      },
      "outputs": [],
      "source": [
        "train_data, valid_data, test_data = {}, {}, {}\n",
        "train_data[\"x\"], train_data[\"y\"], _, train_data[\"c\"] = load_file(TRAIN_PATH)\n",
        "valid_data[\"x\"], valid_data[\"y\"], _, valid_data[\"c\"] = load_file(VALID_PATH)\n",
        "test_data[\"x\"], test_data[\"y\"], _, test_data[\"c\"] = load_file(TEST_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "77a3c6f3",
      "metadata": {
        "id": "77a3c6f3"
      },
      "outputs": [],
      "source": [
        "def display(img, coordinates):\n",
        "    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    cv2.rectangle(new_img, \n",
        "                  (coordinates[0], coordinates[1]),\n",
        "                  (coordinates[0] + coordinates[2], coordinates[1] + coordinates[3]),\n",
        "                  (255,0,0),\n",
        "                  1\n",
        "                 )\n",
        "    while True:\n",
        "        cv2.imshow(\"img\", new_img)\n",
        "        if cv2.waitKey(0) & 0xFF == 27:\n",
        "            cv2.destroyAllWindows()\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a4923d9d",
      "metadata": {
        "id": "a4923d9d"
      },
      "outputs": [],
      "source": [
        "# display(train_data[\"x\"][4000], train_data[\"c\"][4000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "dae9e1d4",
      "metadata": {
        "id": "dae9e1d4"
      },
      "outputs": [],
      "source": [
        "labels = pd.read_csv(\"../raw_data/label_names.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "21c1b079",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "21c1b079",
        "outputId": "36601da7-75ac-4b2d-c6b2-961d9bb3300e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    ClassId                                           SignName\n",
              "0         0                               Speed limit (20km/h)\n",
              "1         1                               Speed limit (30km/h)\n",
              "2         2                               Speed limit (50km/h)\n",
              "3         3                               Speed limit (60km/h)\n",
              "4         4                               Speed limit (70km/h)\n",
              "5         5                               Speed limit (80km/h)\n",
              "6         6                        End of speed limit (80km/h)\n",
              "7         7                              Speed limit (100km/h)\n",
              "8         8                              Speed limit (120km/h)\n",
              "9         9                                         No passing\n",
              "10       10       No passing for vehicles over 3.5 metric tons\n",
              "11       11              Right-of-way at the next intersection\n",
              "12       12                                      Priority road\n",
              "13       13                                              Yield\n",
              "14       14                                               Stop\n",
              "15       15                                        No vehicles\n",
              "16       16           Vehicles over 3.5 metric tons prohibited\n",
              "17       17                                           No entry\n",
              "18       18                                    General caution\n",
              "19       19                        Dangerous curve to the left\n",
              "20       20                       Dangerous curve to the right\n",
              "21       21                                       Double curve\n",
              "22       22                                         Bumpy road\n",
              "23       23                                      Slippery road\n",
              "24       24                          Road narrows on the right\n",
              "25       25                                          Road work\n",
              "26       26                                    Traffic signals\n",
              "27       27                                        Pedestrians\n",
              "28       28                                  Children crossing\n",
              "29       29                                  Bicycles crossing\n",
              "30       30                                 Beware of ice/snow\n",
              "31       31                              Wild animals crossing\n",
              "32       32                End of all speed and passing limits\n",
              "33       33                                   Turn right ahead\n",
              "34       34                                    Turn left ahead\n",
              "35       35                                         Ahead only\n",
              "36       36                               Go straight or right\n",
              "37       37                                Go straight or left\n",
              "38       38                                         Keep right\n",
              "39       39                                          Keep left\n",
              "40       40                               Roundabout mandatory\n",
              "41       41                                  End of no passing\n",
              "42       42  End of no passing by vehicles over 3.5 metric ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d6b4d05-5d53-40a1-afad-dca611f0583e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ClassId</th>\n",
              "      <th>SignName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Speed limit (20km/h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Speed limit (30km/h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Speed limit (50km/h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Speed limit (60km/h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Speed limit (70km/h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Speed limit (80km/h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>End of speed limit (80km/h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Speed limit (100km/h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Speed limit (120km/h)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>No passing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>No passing for vehicles over 3.5 metric tons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>Right-of-way at the next intersection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>Priority road</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>Yield</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>Stop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>No vehicles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>Vehicles over 3.5 metric tons prohibited</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>No entry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>General caution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>Dangerous curve to the left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>Dangerous curve to the right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>Double curve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>Bumpy road</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>Slippery road</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>Road narrows on the right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>Road work</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>Traffic signals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>Pedestrians</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>Children crossing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>Bicycles crossing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>30</td>\n",
              "      <td>Beware of ice/snow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>31</td>\n",
              "      <td>Wild animals crossing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>32</td>\n",
              "      <td>End of all speed and passing limits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>33</td>\n",
              "      <td>Turn right ahead</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>34</td>\n",
              "      <td>Turn left ahead</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>35</td>\n",
              "      <td>Ahead only</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>36</td>\n",
              "      <td>Go straight or right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>37</td>\n",
              "      <td>Go straight or left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>38</td>\n",
              "      <td>Keep right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>39</td>\n",
              "      <td>Keep left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>40</td>\n",
              "      <td>Roundabout mandatory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>41</td>\n",
              "      <td>End of no passing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>42</td>\n",
              "      <td>End of no passing by vehicles over 3.5 metric ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d6b4d05-5d53-40a1-afad-dca611f0583e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d6b4d05-5d53-40a1-afad-dca611f0583e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d6b4d05-5d53-40a1-afad-dca611f0583e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4694f70",
      "metadata": {
        "id": "f4694f70"
      },
      "source": [
        "# Augmentation 1 - Local Histogram Equalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "755abe36",
      "metadata": {
        "id": "755abe36"
      },
      "outputs": [],
      "source": [
        "def local_histogram_equalization(img):\n",
        "    new_img = np.zeros(img.shape, dtype=np.uint8)\n",
        "    new_img[:,:,0] = cv2.equalizeHist(img[:,:,0])\n",
        "    new_img[:,:,1] = cv2.equalizeHist(img[:,:,1])\n",
        "    new_img[:,:,2] = cv2.equalizeHist(img[:,:,2])\n",
        "    return new_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "651c6bd1",
      "metadata": {
        "id": "651c6bd1"
      },
      "outputs": [],
      "source": [
        "new_img = local_histogram_equalization(train_data['x'][4000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "57869e96",
      "metadata": {
        "id": "57869e96"
      },
      "outputs": [],
      "source": [
        "# display(new_img, train_data['c'][4000])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ff34723",
      "metadata": {
        "id": "7ff34723"
      },
      "source": [
        "# Augmentation 2 - Changing Brightness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2e1e6520",
      "metadata": {
        "id": "2e1e6520"
      },
      "outputs": [],
      "source": [
        "def change_brightness(img):\n",
        "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "    img_hsv[:,:,2] = img_hsv[:,:,2] * (0.5 + np.random.uniform(size=(img_hsv.shape[:-1])))\n",
        "    img_rgb = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB)\n",
        "    return img_rgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "067b8c24",
      "metadata": {
        "id": "067b8c24"
      },
      "outputs": [],
      "source": [
        "new_img = change_brightness(train_data['x'][4000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "cf6d07ee",
      "metadata": {
        "id": "cf6d07ee"
      },
      "outputs": [],
      "source": [
        "# display(new_img, train_data['c'][4000])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3159c5a4",
      "metadata": {
        "id": "3159c5a4"
      },
      "source": [
        "# Augmentation 3 - Rotating Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "32429267",
      "metadata": {
        "id": "32429267"
      },
      "outputs": [],
      "source": [
        "def rotation_changing(image):\n",
        "    # Defining angle range\n",
        "    angle_range = 30\n",
        "    # Defining angle rotation\n",
        "    angle_rotation = np.random.uniform(angle_range) - angle_range / 2\n",
        "    # Getting shape of image\n",
        "    rows, columns, channels = image.shape\n",
        "    # Implementing rotation\n",
        "    # Calculating Affine Matrix\n",
        "    affine_matrix = cv2.getRotationMatrix2D((columns / 2, rows / 2), angle_rotation, 1)\n",
        "    # Warping original image with Affine Matrix\n",
        "    rotated_image = cv2.warpAffine(image, affine_matrix, (columns, rows))\n",
        "    # Returning rotated image\n",
        "    return rotated_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "7154d4dd",
      "metadata": {
        "id": "7154d4dd"
      },
      "outputs": [],
      "source": [
        "new_img = rotation_changing(train_data['x'][4000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "76f469e4",
      "metadata": {
        "id": "76f469e4"
      },
      "outputs": [],
      "source": [
        "# display(new_img, train_data['c'][4000])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64f257c8",
      "metadata": {
        "id": "64f257c8"
      },
      "source": [
        "# Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "80035f4d",
      "metadata": {
        "id": "80035f4d"
      },
      "outputs": [],
      "source": [
        "def shuffle(data, seed=0):\n",
        "    new_data = deepcopy(data)\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(new_data[\"x\"])\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(new_data[\"y\"])\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(new_data[\"c\"])\n",
        "    return new_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "de1a50d2",
      "metadata": {
        "id": "de1a50d2"
      },
      "outputs": [],
      "source": [
        "def preprocess(data, shuffle=False, lhe=False, rotate=False, brightness=False):\n",
        "    if shuffle:\n",
        "        data = shuffle(data)\n",
        "    if lhe:\n",
        "        data[\"x\"] = list(map(local_histogram_equalization, tqdm(data[\"x\"])))\n",
        "    if rotate:\n",
        "        data[\"x\"] = list(map(rotation_changing, tqdm(data[\"x\"])))\n",
        "    if brightness:\n",
        "        data[\"x\"] = list(map(rotation_changing, tqdm(data[\"x\"])))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ef40de0a",
      "metadata": {
        "id": "ef40de0a"
      },
      "outputs": [],
      "source": [
        "def join_data(data, augmented_data):\n",
        "    data[\"x\"] = np.r_[data[\"x\"], augmented_data[\"x\"]]\n",
        "    data[\"y\"] = np.r_[data[\"y\"], augmented_data[\"y\"]]\n",
        "    data[\"c\"] = np.r_[data[\"c\"], augmented_data[\"c\"]]\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "4f54e30e",
      "metadata": {
        "id": "4f54e30e"
      },
      "outputs": [],
      "source": [
        "def generate_augmented_data(data):\n",
        "    augmented_data = None\n",
        "    list_kwargs = [\n",
        "        {\"shuffle\": False, \"lhe\": True, \"rotate\": False, \"brightness\": False},\n",
        "        {\"shuffle\": False, \"lhe\": False, \"rotate\": True, \"brightness\": False},\n",
        "        {\"shuffle\": False, \"lhe\": False, \"rotate\": False, \"brightness\": True},\n",
        "        {\"shuffle\": False, \"lhe\": True, \"rotate\": True, \"brightness\": False},\n",
        "        {\"shuffle\": False, \"lhe\": True, \"rotate\": False, \"brightness\": True},\n",
        "        {\"shuffle\": False, \"lhe\": False, \"rotate\": True, \"brightness\": True},\n",
        "        {\"shuffle\": False, \"lhe\": True, \"rotate\": True, \"brightness\": True}\n",
        "    ]\n",
        "    for kwargs in list_kwargs:\n",
        "        data = shuffle(data, np.random.randint(0,100))\n",
        "        data_top = {}\n",
        "        data_top[\"x\"] = data[\"x\"][:int(0.2*len(data[\"x\"]))]\n",
        "        data_top[\"y\"] = data[\"y\"][:int(0.2*len(data[\"x\"]))]\n",
        "        data_top[\"c\"] = data[\"c\"][:int(0.2*len(data[\"x\"]))]\n",
        "        new_data = preprocess(data_top, **kwargs)\n",
        "        if augmented_data is None:\n",
        "            augmented_data = new_data\n",
        "        else:\n",
        "            augmented_data = join_data(new_data, augmented_data)\n",
        "    return join_data(new_data, augmented_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "24195fcf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24195fcf",
        "outputId": "7e5a60cc-7c31-4b68-ae98-639e7ab3a581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6959/6959 [00:00<00:00, 43847.73it/s]\n",
            "100%|██████████| 6959/6959 [00:00<00:00, 32233.45it/s]\n",
            "100%|██████████| 6959/6959 [00:00<00:00, 43242.04it/s]\n",
            "100%|██████████| 6959/6959 [00:00<00:00, 44247.75it/s]\n",
            "100%|██████████| 6959/6959 [00:00<00:00, 38276.49it/s]\n",
            "100%|██████████| 6959/6959 [00:00<00:00, 42314.62it/s]\n",
            "100%|██████████| 6959/6959 [00:00<00:00, 38017.60it/s]\n",
            "100%|██████████| 6959/6959 [00:00<00:00, 41620.97it/s]\n",
            "100%|██████████| 6959/6959 [00:00<00:00, 37802.53it/s]\n",
            "100%|██████████| 6959/6959 [00:00<00:00, 45166.69it/s]\n",
            "100%|██████████| 6959/6959 [00:00<00:00, 40218.43it/s]\n",
            "100%|██████████| 6959/6959 [00:00<00:00, 39647.11it/s]\n",
            "100%|██████████| 882/882 [00:00<00:00, 40324.57it/s]\n",
            "100%|██████████| 882/882 [00:00<00:00, 29343.83it/s]\n",
            "100%|██████████| 882/882 [00:00<00:00, 39739.78it/s]\n",
            "100%|██████████| 882/882 [00:00<00:00, 36426.60it/s]\n",
            "100%|██████████| 882/882 [00:00<00:00, 31850.81it/s]\n",
            "100%|██████████| 882/882 [00:00<00:00, 39272.34it/s]\n",
            "100%|██████████| 882/882 [00:00<00:00, 35716.54it/s]\n",
            "100%|██████████| 882/882 [00:00<00:00, 36690.70it/s]\n",
            "100%|██████████| 882/882 [00:00<00:00, 35063.18it/s]\n",
            "100%|██████████| 882/882 [00:00<00:00, 40544.22it/s]\n",
            "100%|██████████| 882/882 [00:00<00:00, 36139.43it/s]\n",
            "100%|██████████| 882/882 [00:00<00:00, 42518.63it/s]\n"
          ]
        }
      ],
      "source": [
        "augmented_train_data = generate_augmented_data(train_data)\n",
        "augmented_valid_data = generate_augmented_data(valid_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be01d314",
      "metadata": {
        "id": "be01d314"
      },
      "source": [
        "# Labelling Of Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "4b7a9cd8",
      "metadata": {
        "id": "4b7a9cd8"
      },
      "outputs": [],
      "source": [
        "def convert_coordinates_to_yolo_annotation(coordinates, label, shape):\n",
        "    dh, dw, _ = shape\n",
        "    x,y,w,h = coordinates\n",
        "    x_final = x + w if x + w < dw else dw\n",
        "    y_final = y + h if y + h < dh else dh\n",
        "    x_mean = (x + x_final) / (dw * 2)\n",
        "    y_mean = (y + y_final) / (dh * 2)\n",
        "    w_norm = (x_final - x) / dw\n",
        "    h_norm = (y_final - y) / dh\n",
        "    return [\" \".join([str(label), str(x_mean), str(y_mean), str(w_norm), str(h_norm)])]\n",
        "\n",
        "def convert_yolo_annotations_to_coordinates(annotation, shape):\n",
        "    dh, dw, _ = shape\n",
        "    _, x, y, w, h = [float(i) for i in annotation[0].strip().split()]\n",
        "    x_start = (x - w / 2) * dw\n",
        "    y_start = (y - h / 2) * dh\n",
        "    return np.array([x_start, y_start, w * dw, h * dh], dtype=np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "b4143943",
      "metadata": {
        "id": "b4143943"
      },
      "outputs": [],
      "source": [
        "annotation = convert_coordinates_to_yolo_annotation(train_data['c'][4000],\n",
        "                                       train_data['y'][4000],\n",
        "                                       train_data['x'][4000].shape\n",
        "                                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "7c03831b",
      "metadata": {
        "id": "7c03831b"
      },
      "outputs": [],
      "source": [
        "new_coords = convert_yolo_annotations_to_coordinates(annotation, train_data['x'][4000].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "06bd369e",
      "metadata": {
        "id": "06bd369e"
      },
      "outputs": [],
      "source": [
        "# display(train_data['x'][4000] ,new_coords)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58b85b05",
      "metadata": {
        "id": "58b85b05"
      },
      "source": [
        "# Saving new data to file "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "574c37d3",
      "metadata": {
        "id": "574c37d3"
      },
      "outputs": [],
      "source": [
        "def create_directory_structure(root):\n",
        "    try:\n",
        "        os.makedirs(root, exist_ok=True)\n",
        "        folders = [\"train\", \"valid\", \"test\"]\n",
        "        for folder in folders:\n",
        "            path_to_folder = root / folder\n",
        "            os.makedirs(path_to_folder, exist_ok=True)\n",
        "            os.makedirs(path_to_folder / \"images\", exist_ok=True)\n",
        "            os.makedirs(path_to_folder / \"labels\", exist_ok=True)\n",
        "        return True\n",
        "    except:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b7a9dfa1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7a9dfa1",
        "outputId": "0e57f769-731d-425d-9ece-1dfcb982244e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "ROOT_DIR = Path(\"../data/\")\n",
        "create_directory_structure(ROOT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "59b446f8",
      "metadata": {
        "id": "59b446f8"
      },
      "outputs": [],
      "source": [
        "def save_images_and_labels(path, img, label, coordinates):\n",
        "    try:\n",
        "        name = str(uuid.uuid1())\n",
        "        img_name = name + \".jpg\"\n",
        "        label_name = name + \".txt\"\n",
        "        img_path = path / \"images\" / img_name\n",
        "        label_path = path / \"labels\" / label_name\n",
        "        cv2.imwrite(str(img_path), img)\n",
        "        with open(label_path, \"w\") as f:\n",
        "            f.writelines(convert_coordinates_to_yolo_annotation(coordinates, label, img.shape))\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        return str(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "5a0212d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a0212d0",
        "outputId": "f8825f90-df51-4b24-f4bb-18f1addb30f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97426/97426 [00:44<00:00, 2178.33it/s]\n",
            "100%|██████████| 12348/12348 [00:04<00:00, 2583.03it/s]\n",
            " 22%|██▏       | 2792/12630 [00:01<00:04, 2252.44it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in ubyte_scalars\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in ubyte_scalars\n",
            "  \n",
            "100%|██████████| 12630/12630 [00:05<00:00, 2309.66it/s]\n"
          ]
        }
      ],
      "source": [
        "TRAIN_FOLDER = ROOT_DIR / \"train\"\n",
        "VALID_FOLDER = ROOT_DIR / \"valid\"\n",
        "TEST_FOLDER = ROOT_DIR / \"test\"\n",
        "train_result = list(map(lambda img, label, coordinates:save_images_and_labels(TRAIN_FOLDER, img, label, coordinates), tqdm(augmented_train_data[\"x\"]), augmented_train_data[\"y\"], augmented_train_data[\"c\"]))   \n",
        "valid_result = list(map(lambda img, label, coordinates:save_images_and_labels(VALID_FOLDER, img, label, coordinates), tqdm(augmented_valid_data[\"x\"]), augmented_valid_data[\"y\"], augmented_valid_data[\"c\"]))    \n",
        "test_result = list(map(lambda img, label, coordinates:save_images_and_labels(TEST_FOLDER, img, label, coordinates), tqdm(test_data[\"x\"]), test_data[\"y\"], test_data[\"c\"]))                           "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "375c792d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "375c792d",
        "outputId": "fd9c943d-a9c5-496b-d648-9b389620f7e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "for i in test_result:\n",
        "    if i == False:\n",
        "        count += 1\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "1ee03425",
      "metadata": {
        "id": "1ee03425"
      },
      "outputs": [],
      "source": [
        "nc = len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "854cd784",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "854cd784",
        "outputId": "71f72be8-0685-4546-da0f-638394aa095d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "nc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "6d1ddaeb",
      "metadata": {
        "id": "6d1ddaeb"
      },
      "outputs": [],
      "source": [
        "classes = str(list(labels[\"SignName\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "0e8e4d39",
      "metadata": {
        "id": "0e8e4d39"
      },
      "outputs": [],
      "source": [
        "desc = f\"\"\"train: ../data/train/images\n",
        "val: ../data/valid/images\n",
        "test: ../data/test/images\n",
        "\n",
        "nc: {nc}\n",
        "names: {classes}\n",
        "\"\"\"\n",
        "\n",
        "with open(\"../data/data.yaml\", \"w\") as f:\n",
        "    f.write(desc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up yolov5"
      ],
      "metadata": {
        "id": "9l0iqDJHi--f"
      },
      "id": "9l0iqDJHi--f"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDbXb-8HjUGI",
        "outputId": "631b8a76-58f8-455b-fa20-62b217744e4a"
      },
      "id": "FDbXb-8HjUGI",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Traffic-Signs-Detection-Testing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PCBNOHocjW4V",
        "outputId": "93d278c4-8d88-4747-d5b9-4f546c5a89d0"
      },
      "id": "PCBNOHocjW4V",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Traffic-Signs-Detection-Testing'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "939d2062",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "939d2062",
        "outputId": "8f2be924-7bec-4cd0-ef72-08ae645ff893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 13033, done.\u001b[K\n",
            "remote: Total 13033 (delta 0), reused 0 (delta 0), pack-reused 13033\u001b[K\n",
            "Receiving objects: 100% (13033/13033), 11.91 MiB | 24.79 MiB/s, done.\n",
            "Resolving deltas: 100% (9059/9059), done.\n",
            "/content/Traffic-Signs-Detection-Testing/yolov5\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git  # clone repo\n",
        "%cd yolov5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xvJI-AKtjYkN",
        "outputId": "a0717882-2435-4bff-fd1f-64b763627c98"
      },
      "id": "xvJI-AKtjYkN",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Traffic-Signs-Detection-Testing/yolov5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
        "import torch\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "# from utils.google_utils import gdrive_download  # to download models/datasets\n",
        "\n",
        "# clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VOxlg8wjj_Z",
        "outputId": "fb347ce4-48f2-4abb-e909-47a74ef47b3e"
      },
      "id": "4VOxlg8wjj_Z",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 30 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 40 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 440 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 450 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 460 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 471 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 481 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 491 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 501 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 512 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 522 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 532 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 542 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 552 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 563 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 573 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 583 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 593 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 596 kB 5.4 MB/s \n",
            "\u001b[?25hSetup complete. Using torch 1.11.0+cu113 _CudaDeviceProperties(name='Tesla K80', major=3, minor=7, total_memory=11441MB, multi_processor_count=13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cat ../data/data.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsKbuum9joFa",
        "outputId": "81072e3e-8ceb-4826-d20a-09d5fd9283b7"
      },
      "id": "IsKbuum9joFa",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: ../data/train/images\n",
            "val: ../data/valid/images\n",
            "test: ../data/test/images\n",
            "\n",
            "nc: 43\n",
            "names: ['Speed limit (20km/h)', 'Speed limit (30km/h)', 'Speed limit (50km/h)', 'Speed limit (60km/h)', 'Speed limit (70km/h)', 'Speed limit (80km/h)', 'End of speed limit (80km/h)', 'Speed limit (100km/h)', 'Speed limit (120km/h)', 'No passing', 'No passing for vehicles over 3.5 metric tons', 'Right-of-way at the next intersection', 'Priority road', 'Yield', 'Stop', 'No vehicles', 'Vehicles over 3.5 metric tons prohibited', 'No entry', 'General caution', 'Dangerous curve to the left', 'Dangerous curve to the right', 'Double curve', 'Bumpy road', 'Slippery road', 'Road narrows on the right', 'Road work', 'Traffic signals', 'Pedestrians', 'Children crossing', 'Bicycles crossing', 'Beware of ice/snow', 'Wild animals crossing', 'End of all speed and passing limits', 'Turn right ahead', 'Turn left ahead', 'Ahead only', 'Go straight or right', 'Go straight or left', 'Keep right', 'Keep left', 'Roundabout mandatory', 'End of no passing', 'End of no passing by vehicles over 3.5 metric tons']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "with open(\"../data/data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ],
      "metadata": {
        "id": "yOdMdYAIloXH"
      },
      "id": "yOdMdYAIloXH",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J5cCPgCbmCbi",
        "outputId": "51d41443-ed05-463e-e04c-957dfec541b7"
      },
      "id": "J5cCPgCbmCbi",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'43'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cat /content/Traffic-Signs-Detection-Testing/yolov5/models/yolov5s.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk6oO7f2mFL5",
        "outputId": "50e05048-ba35-42ac-fcb7-3d54e6a782f0"
      },
      "id": "Tk6oO7f2mFL5",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# YOLOv5 🚀 by Ultralytics, GPL-3.0 license\n",
            "\n",
            "# Parameters\n",
            "nc: 80  # number of classes\n",
            "depth_multiple: 0.33  # model depth multiple\n",
            "width_multiple: 0.50  # layer channel multiple\n",
            "anchors:\n",
            "  - [10,13, 16,30, 33,23]  # P3/8\n",
            "  - [30,61, 62,45, 59,119]  # P4/16\n",
            "  - [116,90, 156,198, 373,326]  # P5/32\n",
            "\n",
            "# YOLOv5 v6.0 backbone\n",
            "backbone:\n",
            "  # [from, number, module, args]\n",
            "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
            "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
            "   [-1, 3, C3, [128]],\n",
            "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
            "   [-1, 6, C3, [256]],\n",
            "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
            "   [-1, 9, C3, [512]],\n",
            "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
            "   [-1, 3, C3, [1024]],\n",
            "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
            "  ]\n",
            "\n",
            "# YOLOv5 v6.0 head\n",
            "head:\n",
            "  [[-1, 1, Conv, [512, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
            "   [-1, 3, C3, [512, False]],  # 13\n",
            "\n",
            "   [-1, 1, Conv, [256, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
            "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
            "\n",
            "   [-1, 1, Conv, [256, 3, 2]],\n",
            "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
            "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
            "\n",
            "   [-1, 1, Conv, [512, 3, 2]],\n",
            "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
            "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
            "\n",
            "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
            "  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "metadata": {
        "id": "_LrxBgmvmKV2"
      },
      "id": "_LrxBgmvmKV2",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writetemplate /content/Traffic-Signs-Detection-Testing/yolov5/models/custom_yolov5s.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ],
      "metadata": {
        "id": "rP7h1BkumTT8"
      },
      "id": "rP7h1BkumTT8",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train yolov5s on custom data for 100 epochs\n",
        "# time its performance\n",
        "%%time\n",
        "%cd /content/Traffic-Signs-Detection-Testing/yolov5/\n",
        "!python train.py --img 416 --batch 16 --epochs 20 --data '../data/data.yaml' --cfg ./models/custom_yolov5s.yaml --weights 'yolov5s.pt' --name yolov5s_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-dmdvfZmbnK",
        "outputId": "05be8035-60bb-4df0-a9fd-781f8a8730f8"
      },
      "id": "c-dmdvfZmbnK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Traffic-Signs-Detection-Testing/yolov5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=./models/custom_yolov5s.yaml, data=../data/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v6.1-163-gb53917d torch 1.11.0+cu113 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  3    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1    129456  models.yolo.Detect                      [43, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "custom_YOLOv5s summary: 283 layers, 7368368 parameters, 7368368 gradients, 17.2 GFLOPs\n",
            "\n",
            "Transferred 223/369 items from yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight (no decay), 70 weight, 62 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/Traffic-Signs-Detection-Testing/yolov5/../data/train/labels.cache' images and labels... 97426 found, 0 missing, 0 empty, 0 corrupt: 100% 97426/97426 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/Traffic-Signs-Detection-Testing/yolov5/../data/valid/labels' images and labels...12348 found, 0 missing, 0 empty, 0 corrupt: 100% 12348/12348 [00:11<00:00, 1089.41it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Traffic-Signs-Detection-Testing/yolov5/../data/valid/labels.cache\n",
            "Plotting labels to runs/train/yolov5s_results2/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.81 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/yolov5s_results2\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/19      1.7G    0.0347   0.02193   0.07742         4       416: 100% 6090/6090 [1:01:34<00:00,  1.65it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 386/386 [02:49<00:00,  2.27it/s]\n",
            "                 all      12348      12348     0.0218      0.966      0.034     0.0187\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      1/19     1.91G   0.02324   0.01678   0.07536        39       416:  57% 3486/6090 [34:34<25:37,  1.69it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "pE1q5C7an_Ay"
      },
      "id": "pE1q5C7an_Ay",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.plots import plot_results  # plot results.txt as results.png\n",
        "Image(filename='/content/Traffic-Signs-Detection-Testing/yolov5/runs/train/yolov5s_results/results.png', width=1000)"
      ],
      "metadata": {
        "id": "fZu2_IVDuq5H"
      },
      "id": "fZu2_IVDuq5H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GROUND TRUTH TRAINING DATA:\")\n",
        "Image(filename='/content/Traffic-Signs-Detection-Testing/yolov5/runs/train/yolov5s_results/val_batch0_labels.jpg', width=900)"
      ],
      "metadata": {
        "id": "T_Zhzarwu3t3"
      },
      "id": "T_Zhzarwu3t3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n",
        "Image(filename='/content/Traffic-Signs-Detection-Testing/yolov5/runs/train/yolov5s_results/train_batch0.jpg', width=900)"
      ],
      "metadata": {
        "id": "KleYfF5fvAgL"
      },
      "id": "KleYfF5fvAgL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls runs/"
      ],
      "metadata": {
        "id": "_OwdJk7mvU4x"
      },
      "id": "_OwdJk7mvU4x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls runs/train/yolov5s_results/weights"
      ],
      "metadata": {
        "id": "DmeE_Uv4vujV"
      },
      "id": "DmeE_Uv4vujV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov5/\n",
        "!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.5 --source ../data/test/images"
      ],
      "metadata": {
        "id": "NP4y0HUAvx0w"
      },
      "id": "NP4y0HUAvx0w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp2*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "AzjimvRswG27"
      },
      "id": "AzjimvRswG27",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the weights to drive"
      ],
      "metadata": {
        "id": "u6kLVs1Fv53m"
      },
      "id": "u6kLVs1Fv53m"
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "while True:\n",
        "  pass"
      ],
      "metadata": {
        "id": "vcHiXiEiBc4U"
      },
      "id": "vcHiXiEiBc4U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "D8lz-FGjv42P"
      },
      "id": "D8lz-FGjv42P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cp /content/yolov5/runs/train/yolov5s_results/weights/best.pt /content/gdrive/My%20Projects/Traffic-Signs-Testing/"
      ],
      "metadata": {
        "id": "irg5TxzuwOlj"
      },
      "id": "irg5TxzuwOlj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "name": "Traffic Signs Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}